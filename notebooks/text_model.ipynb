{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wLBwwvbwsYGQ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUlSbvSz64n9"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaYR_LHk2DpK"},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from gensim.utils import simple_preprocess\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, ConfusionMatrixDisplay\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import AutoTokenizer, AutoModel, logging\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","logging.set_verbosity_error()"]},{"cell_type":"markdown","metadata":{"id":"90e_pmfu0s-Y"},"source":["## DATA LOADING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STr_f9J4vKBW"},"outputs":[],"source":["sub_path = '/content/drive/MyDrive/khoa_luan/data_04/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1O80NPh1aydM"},"outputs":[],"source":["train_df = pd.read_csv(sub_path + '/train.csv')\n","\n","train_df['author'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3-qigXga2ic"},"outputs":[],"source":["test_df = pd.read_csv(sub_path + '/test.csv')\n","\n","test_df['author'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVWsTodfRdzm"},"outputs":[],"source":["val_df = pd.read_csv(sub_path + '/val.csv')\n","\n","val_df['author'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"0q35l-lyRtvN"},"source":["## MODELING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YzuKolLW-vMg"},"outputs":[],"source":["phobert_type = 'vinai/phobert-base-v2'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbHDipM95uw7"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(phobert_type, use_fast=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqxhsuEg-cyR"},"outputs":[],"source":["class Text_Dataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len, label_encoder, device):\n","      self.df = df\n","      self.max_len = max_len\n","      self.tokenizer = tokenizer\n","      self.label_encoder = label_encoder\n","      self.device = device\n","    def __len__(self):\n","      return len(self.df)\n","\n","    def __getitem__(self, index):\n","      row = self.df.iloc[index]\n","      text, label = self.get_input_data(row)\n","\n","      encoding = self.tokenizer.__call__(\n","          text,\n","          truncation=True,\n","          add_special_tokens=True,\n","          max_length=self.max_len,\n","          padding='max_length',\n","          return_attention_mask=True,\n","          return_token_type_ids=False,\n","          return_tensors='pt',\n","      )\n","\n","      return {\n","          'input_ids': encoding['input_ids'].flatten(),\n","          'attention_mask': encoding['attention_mask'].flatten(),\n","          'target': torch.tensor(label, dtype=torch.long),\n","      }\n","\n","    def get_input_data(self, row):\n","      text = row['lyric']\n","      label = self.label_encoder[row['author']]\n","\n","      return text, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IVOwGUj0Tqy"},"outputs":[],"source":["class Text_Classifier(nn.Module):\n","    def __init__(self, n_classes):\n","        super(Text_Classifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(phobert_type)\n","        bert_out_shape = self.bert.config.hidden_size\n","        self.dense = nn.Sequential(\n","          nn.Linear(bert_out_shape, 512),\n","          nn.Linear(512, 512),\n","          nn.Dropout(p=0.1)\n","        )\n","        self.tanh = nn.Tanh()\n","        self.last_fc = nn.Linear(512, n_classes)\n","\n","    def merged_strategy(self,hidden_states,mode=None):\n","        if mode == 'mean':\n","            outputs = torch.mean(hidden_states, dim=1)\n","        elif mode == 'sum':\n","            outputs = torch.sum(hidden_states, dim=1)\n","        elif mode == 'max':\n","            outputs = torch.max(hidden_states, dim=1)[0]\n","        else:\n","            outputs = hidden_states[:,0]\n","        return outputs\n","\n","    def forward(self, input):\n","        last_hidden_state, output = self.bert(\n","            input_ids=input['input_ids'],\n","            attention_mask=input['attention_mask'],\n","            return_dict=False\n","        )\n","        pooler = self.merged_strategy(last_hidden_state, mode='mean')\n","        x = self.tanh(pooler)\n","        x = self.dense(x)\n","        x = self.tanh(x)\n","        x = self.last_fc(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUalYmMP0boX"},"outputs":[],"source":["def train_single_epoch(model, train_loader, val_loader, loss_func, optimizer, device):\n","    model.train()\n","    train_losses = []\n","    val_losses = []\n","    train_acc = 0\n","    val_acc = 0\n","    for data in train_loader:\n","      input = {\n","          'input_ids': data['input_ids'].to(device),\n","          'attention_mask': data['attention_mask'].to(device)\n","      }\n","      targets = data['target'].to(device)\n","\n","      # calculate loss\n","      outputs = model(input)\n","\n","      loss = loss_func(outputs, targets)\n","      _, predictions = torch.max(outputs, dim=1)\n","      train_acc += torch.sum(predictions == targets)\n","\n","      # backpropagate error and update weights\n","      optimizer.zero_grad()\n","      train_losses.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","\n","    model.eval()\n","    for data in val_loader:\n","      input = {\n","          'input_ids': data['input_ids'].to(device),\n","          'attention_mask': data['attention_mask'].to(device)\n","      }\n","      targets = data['target'].to(device)\n","      # calculate loss\n","      outputs = model(input)\n","      loss = loss_func(outputs, targets)\n","      _, predictions = torch.max(outputs, dim=1)\n","      val_acc += torch.sum(predictions == targets)\n","      val_losses.append(loss.item())\n","\n","    train_acc = train_acc.double()/len(train_loader.dataset)\n","    val_acc = val_acc.double()/len(val_loader.dataset)\n","    train_loss = np.mean(train_losses)\n","    val_loss = np.mean(val_losses)\n","\n","    print(f'Train Accuracy: {train_acc}')\n","    print(f'Validation Accuracy: {val_acc}')\n","    print(f'Train Loss: {train_loss}')\n","    print(f'Validation Loss: {val_loss}')\n","    return train_loss, val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSsE-83LL5RP"},"outputs":[],"source":["def train(model, train_loader, val_loader, loss_func, optimizer, epochs, device):\n","  train_losses = []\n","  val_losses = []\n","  for i in range(epochs):\n","      print(f\"Epoch {i+1}\")\n","      train_loss, val_loss = train_single_epoch(model, train_loader, val_loader, loss_func, optimizer, device)\n","      train_losses.append(train_loss)\n","      val_losses.append(val_loss)\n","      print(\"---------------------------\")\n","  print(\"Finished training\")\n","  return train_losses, val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aG4BGdrI4Tec"},"outputs":[],"source":["def prepare_loaders(train_df, val_df, test_df, max_len, batch_size, label_encoder, device):\n","\n","    train_dataset = Text_Dataset(\n","        df=train_df,\n","        tokenizer=tokenizer,\n","        max_len=max_len,\n","        label_encoder=label_encoder,\n","        device=device)\n","    val_dataset = Text_Dataset(\n","        df=val_df,\n","        tokenizer=tokenizer,\n","        max_len=max_len,\n","        label_encoder=label_encoder,\n","        device=device)\n","    test_dataset = Text_Dataset(\n","        df=test_df,\n","        tokenizer=tokenizer,\n","        max_len=max_len,\n","        label_encoder=label_encoder,\n","        device=device)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    return train_loader, test_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6eRpoNUW9Hf"},"outputs":[],"source":["label_encoder = {\n","    'khắc hưng': 0,\n","    'châu đăng khoa': 1,\n","    'khắc việt': 2,\n","    'phúc trường': 3,\n","    'nguyễn đình vũ': 4,\n","    'mr siro': 5,\n","    'vương anh tú': 6,\n","    'trịnh công sơn': 7,\n","    'phan mạnh quỳnh': 8,\n","    'nguyên chấn phong': 9,\n","    'nguyễn hồng thuận':10,\n","    'nguyễn văn chung': 11,\n","    'phạm trưởng': 12,\n","    'khánh đơn': 13,\n","    'tiên cookie': 14,\n","}\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uT09Eg5-EHXh"},"outputs":[],"source":["MAX_LEN = 256\n","BATCH_SIZE = 24\n","n_classes = len(label_encoder.keys())\n","\n","train_loader, test_loader, val_loader = prepare_loaders(train_df, val_df, test_df, MAX_LEN, BATCH_SIZE, label_encoder, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRBhPJGXsI1l"},"outputs":[],"source":["model = Text_Classifier(n_classes=n_classes).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAdWg5hQJzJc"},"outputs":[],"source":["### Freeze phobert model\n","\n","# for param in model.bert.parameters():\n","#   param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75JJFWS-MZjX"},"outputs":[],"source":["EPOCHS = 30\n","LR = 2e-5\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = AdamW(model.parameters(), lr=LR)\n","\n","train_loss, val_loss = train(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    loss_func=loss_func,\n","    optimizer=optimizer,\n","    epochs=EPOCHS,\n","    device=device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7OniJw8EJBK"},"outputs":[],"source":["epochs = range(1, EPOCHS + 1)\n","# Plot and label the training and validation loss values\n","plt.plot(epochs, train_loss, label='Training Loss')\n","plt.plot(epochs, val_loss, label='Validation Loss')\n","\n","# Add in a title and axes labels\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","\n","# Set the tick locations\n","plt.xticks(range(0, EPOCHS + 1, EPOCHS//10))\n","\n","# Display the plot\n","plt.legend(loc='best')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dnfwtPxGAM6"},"outputs":[],"source":["checkpoint_path = sub_path + 'text_non_freezed_model_checkpoints.pth'\n","model_path = sub_path + 'text_non_freezed_model.pth'\n","\n","checkpoint = {\n","    'epoch': EPOCHS + 1,\n","    'state_dict': model.state_dict(),\n","    'optimizer': optimizer.state_dict()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnPlQxJLs2Rj"},"outputs":[],"source":["torch.save(checkpoint, checkpoint_path)\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhIYbzJTHI--"},"outputs":[],"source":["def load_ckp(checkpoint_fpath, model, optimizer, device):\n","    checkpoint = torch.load(checkpoint_fpath, map_location=torch.device(device))\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer, checkpoint['epoch']\n","\n","def load_model(model_path, model):\n","    weights = torch.load(model_path, map_location=torch.device(device))\n","    model.load_state_dict(checkpoint)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWvJqe8a-lGW"},"outputs":[],"source":["# model, optimizer, epoch = load_ckp(checkpoint_path, model, optimizer, device)\n","# model = load_model(model_path, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYFbVdKgVKzi"},"outputs":[],"source":["def test(model, data_loader):\n","  model.eval()\n","  predicts = []\n","  predict_probs = []\n","  real_values = []\n","\n","  for data in data_loader:\n","      input = {\n","          'input_ids': data['input_ids'].to(device),\n","          'attention_mask': data['attention_mask'].to(device)\n","      }\n","      targets = data['target'].to(device)\n","\n","      total_outs = []\n","      with torch.no_grad():\n","          outputs = model(input)\n","          total_outs.append(outputs)\n","\n","      total_outs = torch.stack(total_outs)\n","      _, pred = torch.max(total_outs.mean(0), dim=1)\n","      predicts.extend(pred)\n","      real_values.extend(targets)\n","\n","  predicts = torch.stack(predicts).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return real_values, predicts\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqr6c6onZULJ"},"outputs":[],"source":["real_values, pred_values = test(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKi38ER7eTRD"},"outputs":[],"source":["print('Precision Score: ', round(precision_score(real_values, pred_values, average='macro'),6))\n","print('Recall Score: ', round(recall_score(real_values, pred_values, average='macro'),6))\n","print('F1 Score: ', round(f1_score(real_values, pred_values, average='macro'),6))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkXDRPAJ1vcv"},"outputs":[],"source":["target_names = label_encoder.keys()\n","print(classification_report(real_values, pred_values, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvGlbyYDyb5T"},"outputs":[],"source":["labels = label_encoder.keys()\n","\n","\n","disp = ConfusionMatrixDisplay.from_predictions(real_values, pred_values, display_labels=labels, cmap='Oranges')\n","\n","\n","plt.xticks(fontsize=8)\n","\n","plt.gcf().autofmt_xdate()\n","plt.show()\n","\n","fig_name = 'text_non_freezed_cm.png'\n","disp.figure_.savefig(sub_path + fig_name, format='png', bbox_inches='tight')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}